\relax 
\citation{Johnson:9MAvkbgy}
\citation{Tan2016Barzilai}
\citation{Barzilai1988Two}
\citation{Shah2016Trading}
\citation{Liu:2015bx}
\citation{Zhang2013Linear}
\citation{Li:2016vh}
\citation{Xiao:2014vw}
\citation{KolteAccelerating}
\citation{Johnson:9MAvkbgy,Tan2016Barzilai,Shah2016Trading}
\citation{Liu:2015bx}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{equa_loss_minimization}{{1}{1}}
\citation{Allen2015Improved}
\citation{Richtarik:2013te}
\citation{Allen2015Improved}
\citation{Johnson:9MAvkbgy}
\citation{Johnson:9MAvkbgy}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related work}{2}}
\newlabel{sectiove_related_work}{{II}{2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \textsc  {SVRG}}}{2}}
\newlabel{SVRG}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Overview}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Speed Maintained SVRG}{2}}
\newlabel{mywork}{{IV}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}smSVRG}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Optimal Choice of the window size}{3}}
\newlabel{secOCCI}{{\unhbox \voidb@x \hbox {IV-B}}{3}}
\newlabel{minform0}{{2}{3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces \textsc  {smSVRG}}}{3}}
\newlabel{smSVRG}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}\textsc  {smSVRG+}}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Numerical Experiments}{3}}
\newlabel{numexperiments}{{V}{3}}
\citation{aaa,bbb}
\newlabel{cmijcnn105}{{1(a)}{4}}
\newlabel{sub@cmijcnn105}{{(a)}{4}}
\newlabel{cmijcnn1005}{{1(b)}{4}}
\newlabel{sub@cmijcnn1005}{{(b)}{4}}
\newlabel{cmijcnn1001}{{1(c)}{4}}
\newlabel{sub@cmijcnn1001}{{(c)}{4}}
\newlabel{cmijcnn10001}{{1(d)}{4}}
\newlabel{sub@cmijcnn10001}{{(d)}{4}}
\newlabel{cmijcnn1}{{\unhbox \voidb@x \hbox {IV-C}}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison of \textsc  {smSVRG}, \textsc  {smSVRG+}, SVRG++, S2GD}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {ijcnn1 $\eta =0.5$}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {ijcnn1 $\eta =0.05$}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {ijcnn1 $\eta =0.01$}}}{4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {ijcnn1 $\eta =0.001$}}}{4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces \textsc  {smSVRG+}}}{4}}
\newlabel{smSVRG+}{{3}{4}}
\newlabel{logistic_reg}{{3}{4}}
\newlabel{ridge_reg}{{4}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Detail information of datasets and models}}{4}}
\newlabel{data information}{{I}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Comparing with existing related methods}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Comparing with SVRG by varying learning rate}{4}}
\newlabel{ijcnn105}{{2(a)}{5}}
\newlabel{sub@ijcnn105}{{(a)}{5}}
\newlabel{ijcnn1005}{{2(b)}{5}}
\newlabel{sub@ijcnn1005}{{(b)}{5}}
\newlabel{ijcnn1001}{{2(c)}{5}}
\newlabel{sub@ijcnn1001}{{(c)}{5}}
\newlabel{ijcnn10001}{{2(d)}{5}}
\newlabel{sub@ijcnn10001}{{(d)}{5}}
\newlabel{figure_logistic_ijcnn}{{\unhbox \voidb@x \hbox {V-A}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Generally, \textsc  {smSVRG} can automatically set an appropriate $m$ with different learning rates for the $l2$-regularized logistic regression}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {ijcnn1 $\eta =0.5$}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {ijcnn1 $\eta =0.05$}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {ijcnn1 $\eta =0.01$}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {ijcnn1 $\eta =0.001$}}}{5}}
\newlabel{a9a03}{{3(a)}{5}}
\newlabel{sub@a9a03}{{(a)}{5}}
\newlabel{a9a005}{{3(b)}{5}}
\newlabel{sub@a9a005}{{(b)}{5}}
\newlabel{a9a002}{{3(c)}{5}}
\newlabel{sub@a9a002}{{(c)}{5}}
\newlabel{a9a0001}{{3(d)}{5}}
\newlabel{sub@a9a0001}{{(d)}{5}}
\newlabel{figure_logistic_a9a}{{\unhbox \voidb@x \hbox {V-A}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Generally, \textsc  {smSVRG} can automatically set an appropriate $m$ with different learning rates for the $l2$-regularized logistic regression}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {a9a $\eta =0.3$}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {a9a $\eta =0.05$}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {a9a $\eta =0.02$}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {a9a $\eta =0.001$}}}{5}}
\newlabel{Year_scale001}{{4(a)}{5}}
\newlabel{sub@Year_scale001}{{(a)}{5}}
\newlabel{Year_scale0005}{{4(b)}{5}}
\newlabel{sub@Year_scale0005}{{(b)}{5}}
\newlabel{Year_scale0002}{{4(c)}{5}}
\newlabel{sub@Year_scale0002}{{(c)}{5}}
\newlabel{Year_scale00001}{{4(d)}{5}}
\newlabel{sub@Year_scale00001}{{(d)}{5}}
\newlabel{figure_linear_scale}{{\unhbox \voidb@x \hbox {V-A}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Generally, \textsc  {smSVRG} can automatically set an appropriate $m$ with different learning rates for the $l2$-regularized linear regression}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {YearPredictionMSD $\eta =0.01$}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {YearPredictionMSD $\eta =0.005$}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {YearPredictionMSD $\eta =0.002$}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {YearPredictionMSD $\eta =0.0001$}}}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{5}}
\newlabel{conclusion}{{VI}{5}}
\bibstyle{plain}
\bibdata{reference}
\bibcite{Allen2015Improved}{{1}{}{{}}{{}}}
\bibcite{Barzilai1988Two}{{2}{}{{}}{{}}}
\bibcite{Defazio:2014vu}{{3}{}{{}}{{}}}
\bibcite{Johnson:9MAvkbgy}{{4}{}{{}}{{}}}
\bibcite{KolteAccelerating}{{5}{}{{}}{{}}}
\bibcite{Liu:2015bx}{{6}{}{{}}{{}}}
\bibcite{Richtarik:2013te}{{7}{}{{}}{{}}}
\bibcite{Li:2016vh}{{8}{}{{}}{{}}}
\bibcite{Schmidt:2013ui}{{9}{}{{}}{{}}}
\bibcite{Shah2016Trading}{{10}{}{{}}{{}}}
\bibcite{ShalevShwartz:2016vy}{{11}{}{{}}{{}}}
\bibcite{Tan2016Barzilai}{{12}{}{{}}{{}}}
\bibcite{Xiao:2014vw}{{13}{}{{}}{{}}}
\bibcite{Zhang2013Linear}{{14}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{cadata01}{{5(a)}{6}}
\newlabel{sub@cadata01}{{(a)}{6}}
\newlabel{cadata005}{{5(b)}{6}}
\newlabel{sub@cadata005}{{(b)}{6}}
\newlabel{cadata002}{{5(c)}{6}}
\newlabel{sub@cadata002}{{(c)}{6}}
\newlabel{cadata0001}{{5(d)}{6}}
\newlabel{sub@cadata0001}{{(d)}{6}}
\newlabel{figure_linear_cadata}{{\unhbox \voidb@x \hbox {V-A}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Generally, \textsc  {smSVRG} can automatically set an appropriate $m$ with different learning rates for the $l2$-regularized linear regression}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {cadata $\eta =0.1$}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {cadata $\eta =0.05$}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {cadata $\eta =0.02$}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {cadata $\eta =0.001$}}}{6}}
